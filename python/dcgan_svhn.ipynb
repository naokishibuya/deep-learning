{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN (DCGAN)\n",
    "\n",
    "In this notebook, I use The **Street View House Numbers (SVHN) Dataset** [[1]](#ref1) to train DCGAN.  \n",
    "\n",
    "If you are not familiar with GAN (Generative Adversarial Network), please see [gan_mnist.ipynb](gan_mnist.ipynb) that explains the concept in details using a simple network.  This notebook is a follow-up on that, and uses more convolutional networks for the generator and the discriminator.\n",
    "\n",
    "The code is based on **Deep Convolutional GANs by Udacity** [[2]](#ref2).  Udacity uses TensorFlow but I use Keras on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SVHN Dataset\n",
    "\n",
    "Download SVHN dataset from the Stanford website if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Uncomment below to download SVHN datasets (it takes some time - a good time for a cup of coffee or two)\n",
    "#\n",
    "#!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
    "#!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in MATLAB format.  We use scipy's `loadmat` to load the data in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = loadmat('train_32x32.mat')\n",
    "test_data  = loadmat('test_32x32.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_data` and `test_data` are `dict` object.  \n",
    "\n",
    "They are the real images of house numbers but the shape is in (image_height, image_width, channels, records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['X'], train_data['y']\n",
    "X_test,  y_test  = test_data['X'],  test_data['y']\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We roll the axis backward to make the shape to (records, image_height, image_width, channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll axis backward\n",
    "\n",
    "X_train = np.rollaxis(X_train, 3)\n",
    "X_test  = np.rollaxis(X_test, 3)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = X_train[np.random.choice(len(X_train), size=80, replace=False)]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(80):\n",
    "    plt.subplot(8, 10, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Deprocessing\n",
    "\n",
    "As usual, we need preprocessing and later deprocessing of the images.  \n",
    "\n",
    "As we will see later on, the generator is using `tanh` activation, for which we need to preprocess the image data into the range between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return (x/255)*2-1\n",
    "\n",
    "def deprocess(x):\n",
    "    return np.uint8((x+1)/2*255) # make sure to use uint8 type otherwise the image won't display properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the preprocessing on the train and test images (and they are the real images as oppose to the generated images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_real = preprocess(X_train)\n",
    "X_test_real  = preprocess(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "The generator takes a latent sample (100 randomly generated numbers) and produces a 32x32 color image that should look like one from the SVHN dataset.\n",
    "\n",
    "The original paper [[3]](#ref3) proposes the following generator network architecture.\n",
    "\n",
    "<img src='../images/dcgan_svhn/generator.png' width='70%'>\n",
    "\n",
    "The generator takes a latent sample which has 100 random numbers.  It uses the fully connected layer to expand the dimension to 4*4*256 neurons so that it can be reshaped into 4x4 2D shape with 256 filters.\n",
    "\n",
    "After that, each layer's height and width are doubled by the transpose convolution and the filters are halved.  The last layer produces a 32x32 2D image with 3 channels.\n",
    "\n",
    "The activation of the output layer is `tanh` which the discriminator expects.\n",
    "\n",
    "In this notebook, I used smaller networks than the original paper [[3]](#ref3) suggests, simply because my linux computer can not handle such a big network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_generator(input_size, leaky_alpha):\n",
    "    # generates images in (32,32,3)\n",
    "    return Sequential([\n",
    "        Dense(4*4*256, input_shape=(input_size,)),\n",
    "        Reshape(target_shape=(4, 4, 256)),                              # 4,4,512\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'), # 8,8,256\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'), # 16,16,128\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Conv2DTranspose(3, kernel_size=5, strides=2, padding='same'),   # 32,32,3\n",
    "        Activation('tanh')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is a classifier to tell if the input image is real or fake.  \n",
    "\n",
    "It is a convolutional neural network that takes a 32x32 image with 3 channels.  The values in the image is expected to be between -1 and 1.\n",
    "\n",
    "The activation of the output layer is `sigmoid` and the discriminator outputs a probability of the image being real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_discriminator(leaky_alpha):\n",
    "    # classifies images in (32,32,3)\n",
    "    return Sequential([        \n",
    "        Conv2D(64, kernel_size=5, strides=2, padding='same',     # 16,16,64\n",
    "               input_shape=(32,32,3)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Conv2D(128, kernel_size=5, strides=2, padding='same'),   # 8,8,128\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Conv2D(256, kernel_size=5, strides=2, padding='same'),   # 4,4,256\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=leaky_alpha),\n",
    "        Flatten(),\n",
    "        Dense(1),\n",
    "        Activation('sigmoid')        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN\n",
    "\n",
    "We connect the generator and the discriminator to make a DCGAN.\n",
    "\n",
    "The input to the DCGAN is a latent sample.  The generator inside DCGAN produces an image which is fed into the discriminator inside the DCGAN.  So, the output of DCGAN is the probability of the generated image being real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# beta_1 is the exponential decay rate for the 1st moment estimates in Adam optimizer\n",
    "def make_DCGAN(sample_size, \n",
    "               g_learning_rate, \n",
    "               g_beta_1,\n",
    "               d_learning_rate,\n",
    "               d_beta_1,\n",
    "               leaky_alpha):\n",
    "    # generator\n",
    "    generator = make_generator(sample_size, leaky_alpha)\n",
    "\n",
    "    # discriminator\n",
    "    discriminator = make_discriminator(leaky_alpha)\n",
    "    discriminator.compile(optimizer=Adam(lr=d_learning_rate, beta_1=d_beta_1), loss='binary_crossentropy')\n",
    "    \n",
    "    # GAN\n",
    "    gan = Sequential([generator, discriminator])\n",
    "    gan.compile(optimizer=Adam(lr=g_learning_rate, beta_1=g_beta_1), loss='binary_crossentropy')\n",
    "    \n",
    "    return gan, generator, discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DCGAN\n",
    "\n",
    "The below is a function to generate latent samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_latent_samples(n_samples, sample_size):\n",
    "    #return np.random.uniform(-1, 1, size=(n_samples, sample_size))\n",
    "    return np.random.normal(loc=0, scale=1, size=(n_samples, sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is a function to set the discriminator to trainable or non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(model, trainable):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is a function to create a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_labels(size):\n",
    "    return np.ones([size, 1]), np.zeros([size, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training DCGAN is essentially the same as training a simple GAN in [gan_mnist.ipynb](gan_mnist.ipynb).\n",
    "\n",
    "* set the discriminator trainable\n",
    "* train the discriminator with real images with the label smoothing   (labels=1-smooth)\n",
    "* train the discriminator with fake images generated by the generator (labels=0)\n",
    "* set the discriminator non-trainable\n",
    "* train the DCGAN with generated images (labels=1)\n",
    "\n",
    "We repeat this process many times until the discriminator loss and the generator loss stabilizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size     = 100     # latent sample size (i.e. 100 random numbers)\n",
    "g_learning_rate = 0.0002  # learning rate for the generator\n",
    "g_beta_1        = 0.9     # the exponential decay rate for the 1st moment estimates in Adam optimizer\n",
    "d_learning_rate = 0.001   # learning rate for the discriminator\n",
    "d_beta_1        = 0.9     # the exponential decay rate for the 1st moment estimates in Adam optimizer\n",
    "leaky_alpha     = 0.01\n",
    "epochs          = 100\n",
    "batch_size      = 16      # train batch size\n",
    "eval_size       = 16      # evaluate size\n",
    "smooth          = 0.1\n",
    "\n",
    "# labels for the batch size and the test size\n",
    "y_train_real, y_train_fake = make_labels(batch_size)\n",
    "y_eval_real,  y_eval_fake  = make_labels(eval_size)\n",
    "\n",
    "# create a GAN, a generator and a discriminator\n",
    "gan, generator, discriminator = make_DCGAN(\n",
    "    sample_size, \n",
    "    g_learning_rate, \n",
    "    g_beta_1,\n",
    "    d_learning_rate,\n",
    "    d_beta_1,\n",
    "    leaky_alpha)\n",
    "\n",
    "losses = []\n",
    "for e in range(epochs):\n",
    "    for i in range(len(X_train_real)//batch_size):\n",
    "        # real MNIST digit images\n",
    "        X_batch_real = X_train_real[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # latent samples and the generated digit images\n",
    "        latent_samples = make_latent_samples(batch_size, sample_size)\n",
    "        X_batch_fake = generator.predict_on_batch(latent_samples)\n",
    "        \n",
    "        # train the discriminator to detect real and fake images\n",
    "        make_trainable(discriminator, True)\n",
    "        discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n",
    "        discriminator.train_on_batch(X_batch_fake, y_train_fake)\n",
    "\n",
    "        # train the generator via GAN\n",
    "        make_trainable(discriminator, False)\n",
    "        gan.train_on_batch(latent_samples, y_train_real)\n",
    "    \n",
    "    # evaluate\n",
    "    X_eval_real = X_test_real[np.random.choice(len(X_test_real), eval_size, replace=False)]\n",
    "    \n",
    "    latent_samples = make_latent_samples(eval_size, sample_size)\n",
    "    X_eval_fake = generator.predict_on_batch(latent_samples)\n",
    "\n",
    "    d_loss = discriminator.test_on_batch(X_eval_real, y_eval_real)\n",
    "    d_loss = discriminator.test_on_batch(X_eval_fake, y_eval_fake)\n",
    "    g_loss = gan.test_on_batch(latent_samples, y_eval_real) # we want the fake to be realistic!\n",
    "    \n",
    "    losses.append((d_loss, g_loss))\n",
    "    \n",
    "    print(\"Epoch: {:>3}/{} Discriminator Loss: {:>6.4f} Generator Loss: {:>6.4f}\".format(\n",
    "        e+1, epochs, d_loss, g_loss))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The discriminator loss and the generator loss are shown below.  They both kind of stabilizes in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(losses.T[0], label='Discriminator')\n",
    "plt.plot(losses.T[1], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate new images using the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_samples = make_latent_samples(80, sample_size)\n",
    "generated_digits = generator.predict(latent_samples)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(80):\n",
    "    img = deprocess(generated_digits[i])\n",
    "    ax = plt.subplot(8, 10, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Beta 1 Parameters\n",
    "\n",
    "In the original DCGAN paper [[3]](#ref3), 0.5 is used for `beta_1` (the exponential decay rate for the 1st moment estimate that the Adam optimizer [[4]](#ref4) uses).  Adam uses an exponential average of weight gradients like the Momentum optimizer so that it keeps the momentum of weight updates and avoid random spikes and speed up/down as the momentum goes.\n",
    "\n",
    "According to the original DCGAN paper [[3]](#ref3), it stabilizes the training better.\n",
    "\n",
    "> we found leaving the momentum term Î²1 at the suggested value of 0.9 resulted in training oscillation and instability while reducing it to 0.5 helped stabilize training.\n",
    "\n",
    "The generator in this project is not exactly the same as in the DCGAN paper [[3]](#ref3) but I also tried the following hyterparameters (attention to the g_beta_1 and d_beta_1).\n",
    "\n",
    "```\n",
    "sample_size     = 100     # latent sample size (i.e. 100 random numbers)\n",
    "g_learning_rate = 0.0001  # learning rate for the generator\n",
    "g_beta_1        = 0.5     # the exponential decay rate for the 1st moment estimates in Adam optimizer\n",
    "d_learning_rate = 0.001   # learning rate for the discriminator\n",
    "d_beta_1        = 0.5     # the exponential decay rate for the 1st moment estimates in Adam optimizer\n",
    "leaky_alpha     = 0.01\n",
    "epochs          = 100\n",
    "batch_size      = 16      # train batch size\n",
    "eval_size       = 16      # evaluate size\n",
    "smooth          = 0.1\n",
    "```\n",
    "\n",
    "The generated images with beta_1 = 0.5 is not good with the networks I used.  I believe it depends on other hyperparameters and the network structure as well.\n",
    "\n",
    "<img src='../images/dcgan_svhn/losses.png'  align='left'/>\n",
    "<img src='../images/dcgan_svhn/generated.png' align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id=\"ref1\"></a>\n",
    "### [1] The Street View House Numbers (SVHN) Dataset\n",
    "\n",
    "Stanford\n",
    "\n",
    "http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "<a id=\"ref2\"></a>\n",
    "### [2] Deep Convolutional GANs\n",
    "\n",
    "Udacity\n",
    "\n",
    "https://github.com/udacity/deep-learning/blob/master/dcgan-svhn/DCGAN.ipynb\n",
    "\n",
    "<a id=\"ref3\"></a>\n",
    "### [3] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "\n",
    "Alec Radford & Luke Metz (indico Research), Soumith Chintala (Facebook AI Research)\n",
    "\n",
    "https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "<a id=\"ref4\"></a>\n",
    "### [4] ADAM: A Method for Stocastic Optimization\n",
    "\n",
    "Diederik P. Kingma (University of Amsterdam, OpenAI), Jimmy Lei Ba (University of Toronto)\n",
    "\n",
    "https://arxiv.org/pdf/1412.6980.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
